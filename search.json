[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methods in evolutionary ecology WS25/26",
    "section": "",
    "text": "About\nThis script covers the computational and bioinformatics parts of the module “Methods in Evolutionary Ecology”. We will introduce you to R and BASH, two of the most widely used scripting languages, and make you familiar with navigating in a UNIX environment. These skills are important for any biologist, irrespective of the field you may want to specialise in in the future. Building upon your new knowledge, we will learn how to reconstruct phylogenies from sequencing data, how to work with genomic data, and how to characterise microbiomes. At the end of three weeks computational work, you will tackle a small computational group project, putting your new skills into practise.\nThe script is designed to cover the entire course content. While we will go you through all of the material together in detail during the course, the script should also enable you to work through the content on your own, e.g., to recap after the course has finished and as a reference and starting point for future computational endeavours.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "Methods in evolutionary ecology WS25/26",
    "section": "Quarto",
    "text": "Quarto\nThe text is formatted using Quarto, which comes with a number of benefits. It allows us to provide explanations as structured and nicely formatted regular text, and to include code blocks for all computational steps. When compiling Quarto documents, all of the code is run, which means that you not only see the code, but also the outputs it creates.\nHere is an example:\nThis little block of R code generates 100 random coordinates and plots them. The code is shown below, together with the output the code has produced (in this case, a plot).\n\nx &lt;- runif(100)\ny &lt;- runif(100)\nplot(x, y)\n\n\n\n\n\n\n\n\nThe code can conveniently be copied from the block into your own scripts.\nQuarto supports many formats, we here provide the script as a webpage and a printable pdf. Writing Quarto documents is very simple and can be done using RStudio as an editor. The entire script is available for you on github – feel free to download it and modify it with your own comments, notes, and code. We will provide a short introduction to github and Quarto in the course.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#how-to-find-your-way-around",
    "href": "index.html#how-to-find-your-way-around",
    "title": "Methods in evolutionary ecology WS25/26",
    "section": "How to find your way around",
    "text": "How to find your way around\nSimply use the navigation on the left to quickly access the different topics, or flip through the individual pages using the buttons at the bottom of the page. You may wish to download the pdf version of the script (click the pdf icon in the top left) which is ideal for printing. The script is organized by topics, rather than course days, because we will adapt the tempo according to your needs.\n\nPlease note: The script will very likely only be complete at the end of the course. We will still be modifying and correcting it throughtout the three weeks you are with us. So make sure to check out the final version at the end of the course.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "Rintro1.html",
    "href": "Rintro1.html",
    "title": "1  First steps",
    "section": "",
    "text": "1.1 Operators and functions\nR is a statistical programming environment that has become a standard tool in the data and life sciences and many other fields. You may have used R already to run some statistics in a course you took in your studies, and this will be a likely use case for your remaining degree. However, R is much more: it can be used to analyse massive the datasets of the “omics”- age, build webpages, blogs, and interactive apps, and even for art!\nBefore taking full advantage of what the various R packages have to offer, we need to become familiar with its basic structure and commands. It pays off to invest a little effort in practicing the basics, because all R packages use the same syntax – a solid familiarity with base R thus allows you to explore the entire R universe independently.\nR can be used just like an arithmetic calculator. You are familiar with all of the basic syntax already, if you know how to use a calculator!\nSome examples:\n3 + 4  \n\n[1] 7\n\n3 - 4  \n\n[1] -1\n\n3 * 4  \n\n[1] 12\n\n3 / 4  \n\n[1] 0.75\n\n3 ^ 4  # power of\n\n[1] 81\nAs with a regular calculator, there is operator precedence: power &gt; multiplicative operations &gt; additive operations:\n(1 + 2) * 3\n\n[1] 9\n\n2^3 * 3\n\n[1] 24\n\n2^(3 * 3)\n\n[1] 512\nSquare roots, exponentials, and logarithms also work just as with a calculator:\nsqrt(9) \n\n[1] 3\n\nexp(3) \n\n[1] 20.08554\n\nlog(3) \n\n[1] 1.098612\n\nlog(exp(3)) # natural logarithm\n\n[1] 3\n\nlog10(100)  # logarithm to base 10\n\n[1] 2\nIn order to “save” a value for use later on, you have to assign it to a variable! &lt;- is the assignment operator you need to use for this (handy shortcut in RStudio is ALT + -).\nx &lt;- 3 + 4\nCalling the variable will then print the result to the R console, and can be used in other calculations.\nx\n\n[1] 7\n\nx + 10\n\n[1] 17\nYou can call your variables whatever you want, but be careful: R will overwrite any variable if you tell it to, without a warning! You should also avoid giving your variables names that are already assigned to functions.\nmy_favourite_variable &lt;- 100\nmy_favourite_variable\n\n[1] 100\nAll variables (among other things) are visible in the environment panel in RStudio (default: top right part of the screen).",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First steps</span>"
    ]
  },
  {
    "objectID": "Rintro1.html#operators-and-functions",
    "href": "Rintro1.html#operators-and-functions",
    "title": "1  First steps",
    "section": "",
    "text": "“=” can also be used to assign variables but is discouraged, because the direction of the assignment is not immediately obvious. It is best practise to always start with the variable, followed by the assignment operator",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First steps</span>"
    ]
  },
  {
    "objectID": "Rintro1.html#data-types",
    "href": "Rintro1.html#data-types",
    "title": "1  First steps",
    "section": "1.2 Data types",
    "text": "1.2 Data types\nYou need to be familiar with at least three important data types in R: logical, numeric, and character. Data being stored in a different data type than required is one of the most frequent error messages you will encounter as an R beginner.\nlogical simply means true or false. R also understands the abbreviations T and F. To determine which types you data is in, you can use mode or class.\n\nvar1 &lt;- FALSE \nmode(var1)\n\n[1] \"logical\"\n\n\nnumeric means numbers\n\nvar2 &lt;- 10\nclass(10)\n\n[1] \"numeric\"\n\n\nA character is any form of text, a so called “string”. It must always be surrounded by quotation marks!\n\nvar3 &lt;- \"A so called string\"\nmode(var3)\n\n[1] \"character\"\n\n\nIf in doubt, R will often convert or read in data as characters. Watch out for some common errors!\n\nvar4 &lt;- \"5\"\nvar4\n\n[1] \"5\"\n\nis.numeric(var4)\n\n[1] FALSE\n\nvar5 &lt;- \"TRUE\"\nvar5\n\n[1] \"TRUE\"\n\nis.logical(var5)\n\n[1] FALSE\n\n\nYou can convert between types easily!\n\nvar6 &lt;- as.numeric(var4)\nvar6\n\n[1] 5\n\nclass(var6)\n\n[1] \"numeric\"",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First steps</span>"
    ]
  },
  {
    "objectID": "Rintro1.html#exercises",
    "href": "Rintro1.html#exercises",
    "title": "1  First steps",
    "section": "1.3 Exercises",
    "text": "1.3 Exercises\n\nSum the values of 1 to 5\n\n\nsum(1:5)\n\n[1] 15\n\n1 + 2 + 3 + 4 + 5\n\n[1] 15\n\n\n\nCreate a variable v1 and assign it a character value\n\n\nv1 &lt;- \"text\"\n\n\nCopy variable v1 to v2\n\n\nv2 &lt;- v1\n\n\nCompare the value of v1 against v2\n\n\nv1 == v2\n\n[1] TRUE\n\nidentical(v1, v2)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nTipTip\n\n\n\nCompare values and variables using the following operators\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nequals\n\n\n!=\nnot equal\n\n\n\nPlease note, = and == do very different things! Don’t mix them up.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First steps</span>"
    ]
  },
  {
    "objectID": "Rintro2.html",
    "href": "Rintro2.html",
    "title": "2  Data structures",
    "section": "",
    "text": "2.1 Vectors\nSo far we’ve only looked at simple variables consisting of a single value or character. Typically, your data will be more complex. In R, there are three structures relevant for the data you will be working with.\nA vector is a number of elements of the same data type (logical, numeric, character). It can be generated by concatenating the elements using the function c.\nvec1 &lt;- c(T, F, T, F)\nvec1\n\n[1]  TRUE FALSE  TRUE FALSE\n\nmode(vec1)\n\n[1] \"logical\"\n\nvec2 &lt;- c(1, 2, 3, 4, 5)\nvec2\n\n[1] 1 2 3 4 5\n\nmode(vec2)\n\n[1] \"numeric\"\n\nvec3 &lt;- c(\"Spring\", \"Summer\", \"Autumn\", \"Winter\")\nvec3\n\n[1] \"Spring\" \"Summer\" \"Autumn\" \"Winter\"\n\nmode(vec3)\n\n[1] \"character\"\nOther ways to generate vectors are rep and seq. rep is used to repeat any number of elements any number of times.\nrep(5, 10)\n\n [1] 5 5 5 5 5 5 5 5 5 5\n\nrep(vec3, 5)\n\n [1] \"Spring\" \"Summer\" \"Autumn\" \"Winter\" \"Spring\" \"Summer\" \"Autumn\" \"Winter\"\n [9] \"Spring\" \"Summer\" \"Autumn\" \"Winter\" \"Spring\" \"Summer\" \"Autumn\" \"Winter\"\n[17] \"Spring\" \"Summer\" \"Autumn\" \"Winter\"\nseq can be used to create numerical sequences.\nseq(from = 0, to = 100, by = 5)\n\n [1]   0   5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n[20]  95 100\nThe command above is easy to read and understand for humans, which is good. R will also understand if you specify it as\nseq(0, 100, 5)\n\n [1]   0   5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n[20]  95 100\nAs a shortcut for a common sequences, you can use\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\nAs mentioned above,, vectors can only combine elements of a single data type. Combining multiple different data types may result in some unwanted behaviour.\nvec_mix1 &lt;- c(5, TRUE, 65)\nmode(vec_mix1)\n\n[1] \"numeric\"\n\nvec_mix2 &lt;- c(\"blue\", TRUE, \"red\")\nmode(vec_mix2)\n\n[1] \"character\"\nIn many cases you may wish to access a single element of a vector. You can do so using square brackets.\nz &lt;- c(\"order\", \"family\", \"genus\", \"species\")\nz[2]\n\n[1] \"family\"\nSimilarly, you can access any combination of elements from the vector.\nz[1:2]\n\n[1] \"order\"  \"family\"\n\ni &lt;- c(1, 3)\nz[i]\n\n[1] \"order\" \"genus\"\n\nz[c(1, 1, 1, 4)]\n\n[1] \"order\"   \"order\"   \"order\"   \"species\"\n\nz[-1]\n\n[1] \"family\"  \"genus\"   \"species\"\nThe square brackets are also used if you need to change elements of the vector. Changes are made using the assignment operator which you already know.\nx &lt;- 1:5\nx\n\n[1] 1 2 3 4 5\n\nx[c(1, 4)] &lt;- 10\nx\n\n[1] 10  2  3 10  5\nWhich elements of a vector have certain characteristics? This is important for filtering/selecting in your dataset. You can combine different queries using logical operators.\nx &gt;= 5\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\nx[x &gt;= 5]\n\n[1] 10 10  5\n\nwhich(x &gt;= 5)\n\n[1] 1 4 5\n\nz\n\n[1] \"order\"   \"family\"  \"genus\"   \"species\"\n\nwhich(z == \"genus\")\n\n[1] 3\n\nz[z== \"genus\"]\n\n[1] \"genus\"\n\nz[z != \"genus\"]\n\n[1] \"order\"   \"family\"  \"species\"\n\nwhich(z== \"genus\" | z == \"order\")\n\n[1] 1 3\nLogical operators in R\nConveniently, the elements of a vector can be named and accessed using the names. Let’s first create a vector…\ndmel &lt;- c(\"Hexapoda\", \"Diptera\", \"Drosophilidae\", \"Drosophila\", \"Drosophila melanogaster\")\ndmel\n\n[1] \"Hexapoda\"                \"Diptera\"                \n[3] \"Drosophilidae\"           \"Drosophila\"             \n[5] \"Drosophila melanogaster\"\n… and then add names for each element\nnames(dmel) &lt;- c(\"Class\", \"Order\", \"Family\", \"Genus\", \"Species\")\ndmel\n\n                    Class                     Order                    Family \n               \"Hexapoda\"                 \"Diptera\"           \"Drosophilidae\" \n                    Genus                   Species \n             \"Drosophila\" \"Drosophila melanogaster\" \n\nstr(dmel)\n\n Named chr [1:5] \"Hexapoda\" \"Diptera\" \"Drosophilidae\" \"Drosophila\" ...\n - attr(*, \"names\")= chr [1:5] \"Class\" \"Order\" \"Family\" \"Genus\" ...\nNow we can use the names to access the values\ndmel[c(\"Class\", \"Species\")]\n\n                    Class                   Species \n               \"Hexapoda\" \"Drosophila melanogaster\" \n\ndmel[names(dmel) == \"Order\"]\n\n    Order \n\"Diptera\"",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data structures</span>"
    ]
  },
  {
    "objectID": "Rintro2.html#vectors",
    "href": "Rintro2.html#vectors",
    "title": "2  Data structures",
    "section": "",
    "text": "|\nOR\n\n\n&\nAND\n\n\n!\nNOT\n\n\n\n\n\n\n\n\n\n\n2.1.1 Exercises\n\nCreate a vector consecutively numbering all days of the year 2026. Assign the correct weekday names for all elements of the vector.\nUse the vector to determine how many days in 2026 are weekend days.\n\n\n\n\n\n\n\nTipTip\n\n\n\nIf you struggle to assign the correct names, have a look at the help for rep.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data structures</span>"
    ]
  },
  {
    "objectID": "Rintro2.html#matrices",
    "href": "Rintro2.html#matrices",
    "title": "2  Data structures",
    "section": "2.2 Matrices",
    "text": "2.2 Matrices\nA matrix in R can be thought of as a two-dimensional vector. All elements must be of the same data type. There are various ways to create a matrix. For example, one can use the matrix function like this.\n\nmat1 &lt;- matrix(data = 1:12, nrow = 3, ncol = 4, byrow=T) \nmat1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\nAlternatively, a vector can be transformed into a matrix\n\nmat2 &lt;- 1:12\ndim(mat2) &lt;- c(3, 4)\nmat2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n\nOften you will want to combine multiple vectors into a matrix\n\ndmel &lt;- c(\"Hexapoda\", \"Diptera\", \"Drosophilidae\", \"Drosophila\", \"Drosophila melanogaster\")\ndhyd &lt;- c(\"Hexapoda\", \"Diptera\", \"Drosophilidae\", \"Drosophila\", \"Drosophila hydei\")\nmat3 &lt;- cbind(dmel, dhyd)\nmat3\n\n     dmel                      dhyd              \n[1,] \"Hexapoda\"                \"Hexapoda\"        \n[2,] \"Diptera\"                 \"Diptera\"         \n[3,] \"Drosophilidae\"           \"Drosophilidae\"   \n[4,] \"Drosophila\"              \"Drosophila\"      \n[5,] \"Drosophila melanogaster\" \"Drosophila hydei\"\n\nmat4 &lt;- rbind(dmel, dhyd)\nmat4\n\n     [,1]       [,2]      [,3]            [,4]        \ndmel \"Hexapoda\" \"Diptera\" \"Drosophilidae\" \"Drosophila\"\ndhyd \"Hexapoda\" \"Diptera\" \"Drosophilidae\" \"Drosophila\"\n     [,5]                     \ndmel \"Drosophila melanogaster\"\ndhyd \"Drosophila hydei\"       \n\n\nJust like vectors, matrix elements can have names\n\nmat3\n\n     dmel                      dhyd              \n[1,] \"Hexapoda\"                \"Hexapoda\"        \n[2,] \"Diptera\"                 \"Diptera\"         \n[3,] \"Drosophilidae\"           \"Drosophilidae\"   \n[4,] \"Drosophila\"              \"Drosophila\"      \n[5,] \"Drosophila melanogaster\" \"Drosophila hydei\"\n\ncolnames(mat3)\n\n[1] \"dmel\" \"dhyd\"\n\nrownames(mat3) &lt;- c(\"Class\", \"Order\", \"Family\", \"Genus\", \"Species\")\nmat3\n\n        dmel                      dhyd              \nClass   \"Hexapoda\"                \"Hexapoda\"        \nOrder   \"Diptera\"                 \"Diptera\"         \nFamily  \"Drosophilidae\"           \"Drosophilidae\"   \nGenus   \"Drosophila\"              \"Drosophila\"      \nSpecies \"Drosophila melanogaster\" \"Drosophila hydei\"\n\n\nAnd just like with vectors, we can use square brackets to access and replace values. Because there are 2 dimensions, we need to provide 2 values (one for rows, one for columns, separated by ,).\n\nmat3\n\n        dmel                      dhyd              \nClass   \"Hexapoda\"                \"Hexapoda\"        \nOrder   \"Diptera\"                 \"Diptera\"         \nFamily  \"Drosophilidae\"           \"Drosophilidae\"   \nGenus   \"Drosophila\"              \"Drosophila\"      \nSpecies \"Drosophila melanogaster\" \"Drosophila hydei\"\n\nmat3[1:3, 2]\n\n          Class           Order          Family \n     \"Hexapoda\"       \"Diptera\" \"Drosophilidae\" \n\nmat3[1:3, ]\n\n       dmel            dhyd           \nClass  \"Hexapoda\"      \"Hexapoda\"     \nOrder  \"Diptera\"       \"Diptera\"      \nFamily \"Drosophilidae\" \"Drosophilidae\"\n\nmat3[c(\"Class\", \"Species\"), ]\n\n        dmel                      dhyd              \nClass   \"Hexapoda\"                \"Hexapoda\"        \nSpecies \"Drosophila melanogaster\" \"Drosophila hydei\"\n\n\n\n2.2.1 Exercise\n\ncreate a matrix using with 20 rows & 5 columns, using 100 randomly generated numbers between 0 and 1000.\n\n\nrandom_numbers &lt;- runif(100, 0, 1000)\n\n\nmatrix(data = runif(100, 0, 1000), nrow = 20)\n\n           [,1]       [,2]      [,3]     [,4]      [,5]\n [1,] 767.44274 142.794480  74.30895 162.5967 733.17794\n [2,] 818.20863 259.213223 845.11148 828.2769 383.49636\n [3,] 810.78160 723.726430 559.28120 592.3877 884.27047\n [4,] 117.68542 696.657457 725.90583 229.3494 321.05045\n [5,] 216.63601 932.052773 877.00584 355.2922 300.09713\n [6,] 424.36509 938.569972 237.83498 828.7951  18.70234\n [7,] 732.31911 243.426767 361.47000 918.6077  73.19164\n [8,] 155.33274  87.253002 632.69128 691.6677  67.33543\n [9,]  57.91474 129.019608 497.76675 879.7044 375.47574\n[10,]  68.12413 473.083045 971.27915 692.5706 975.12205\n[11,] 287.38774 555.837265 936.07177 169.3397 200.56228\n[12,] 490.13888 192.930254 834.95554 938.2065 524.75202\n[13,] 669.34385   6.175887 976.18835 864.0994 343.56647\n[14,] 374.36874 883.997070 228.96363 744.5223 844.23102\n[15,] 790.85627 544.074341 661.87802 969.4943 639.50680\n[16,] 883.95879 107.542781 305.79600 267.2784 939.35474\n[17,] 203.79681 937.134721 705.20010 830.1327 610.22311\n[18,] 322.34544 265.109798 679.45018 695.2518 297.51385\n[19,] 727.08828 338.383000 984.32850 715.8891 535.28252\n[20,] 454.67098 529.967898 768.24483 646.6106 388.89908\n\n\n\nreplace all values in the 3rd column of this matrix that are larger than 500 with NA.\n\n\n\n\n\n\n\nTipTip\n\n\n\nuse the function runif to create random values",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data structures</span>"
    ]
  },
  {
    "objectID": "Rintro2.html#data-frames",
    "href": "Rintro2.html#data-frames",
    "title": "2  Data structures",
    "section": "2.3 Data frames",
    "text": "2.3 Data frames\nData frames are the R equivalent of spread sheets. Like matrices, they are two-dimensional, however they may combine different data types. Most biological data sets you will encounter will be data frames.\nLets create a data frame\n\n# create some data\nspecies &lt;- rep(c(\"beech\",\"ash\",\"elm\",\"maple\", \"sycamore\"),40)\nspecies\n\n  [1] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n  [7] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [13] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [19] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [25] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [31] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [37] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [43] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [49] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [55] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [61] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [67] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [73] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [79] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [85] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [91] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [97] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[103] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[109] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[115] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[121] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[127] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[133] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[139] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[145] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[151] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[157] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[163] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[169] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[175] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[181] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[187] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[193] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[199] \"maple\"    \"sycamore\"\n\ndbh &lt;- runif(200, 5, 40)\ndbh\n\n  [1] 26.768398 39.423180 35.882841 29.460853 25.695094 19.054656  9.994555\n  [8] 20.308964 16.365927  6.407455 28.069851 11.599295 11.130383 15.418817\n [15] 25.281858 10.799714 21.010647 21.547930 25.487683 15.524904 38.381207\n [22] 36.775344 29.008318 13.539389 24.688984 26.179514 19.980015 30.282379\n [29] 33.026252 10.365488 31.702487 16.876523 23.625668 33.716650 11.885797\n [36] 34.182978 26.434626 39.274388  9.281975 10.883582 23.372963 14.684039\n [43] 28.104645 31.338463 34.480671 19.512009 39.210487 17.078271 34.737907\n [50] 33.241687 37.803986  7.511690 10.219120 23.024146 16.353940 15.675558\n [57]  5.900811 24.780468  9.546775  9.790271 36.651205 36.575235 16.932777\n [64] 12.329777 36.617990 25.989670 12.010707 27.209153 26.802109 24.337133\n [71] 36.751729 24.845354 28.017108  5.513428 28.867617 37.719178 25.807664\n [78] 29.314910 34.460700 26.015800 21.118577  9.391043 18.643630 18.458766\n [85]  8.544874  6.625270 35.162203 27.947152 28.381249  9.707669 18.540145\n [92] 27.162094 17.075501 22.794281 26.032802 38.578573 14.156590 12.640182\n [99]  7.960514  6.363974 36.678844 36.948906  7.376001 34.122996 19.807357\n[106] 26.332423 26.525663 26.798339 21.223889 30.085657 31.471639 32.119809\n[113] 23.233763 18.844977 38.160660 15.309211 21.811952 19.270793 21.105481\n[120] 36.032946 33.703118 29.360035  8.859233 22.031908 15.216530  8.933494\n[127] 16.323009 10.020720 32.126095 14.020323 21.624739 19.331251 28.803747\n[134] 35.244321 28.361724 33.376500 35.902703 30.434059 17.140473 11.650636\n[141] 21.339425 37.947323  7.558763 12.214690 20.694615 19.401372  7.834640\n[148] 10.457963 12.769943 14.475871 15.204712 10.473519 36.186902 33.372648\n[155]  5.179415  6.316966 37.893776 27.382259 18.735048  8.202685 33.713332\n[162]  5.563844  8.847758 22.146751 22.027691  5.956485 31.636804 23.728416\n[169] 38.390701  5.189294 20.919704 25.918542 29.530533 33.011680 18.053345\n[176] 13.442076 18.650912 36.220429 10.730331 33.934505 17.078683 17.060906\n[183] 21.307797 19.294529 17.019305 17.721625 27.200437 34.682993 14.300489\n[190] 21.472397  8.444422  8.803539 14.076849 38.721602 31.234574  6.891242\n[197] 11.358812 33.576984 34.158067 27.072882\n\nage &lt;- as.integer(runif(200, 20, 120))\nage\n\n  [1] 100  68  35  59  36  26  50  58 109  24  75  23  88  27  28 108  30  26\n [19]  94 107  48  32  94  55  40  31  59  33 115  20  41  87  35  56  66  72\n [37] 100  59 118  28  38  74 115  94  59  70  61 115  78  63  65  51  44 111\n [55]  44  70  91  57  50 119  23  41 117  47  53  51  24  38 105  72  91 110\n [73] 109 118  97  26  23  32 113  94 113 119  42 105  79  32 100  87  72 102\n [91] 102  38  22  68  69  90  71 107  50  38  50 111  30  63 111  98  81 115\n[109]  20  35  91  26  42  41  22  89  87  36  59  86  37  41  85  59 109 112\n[127]  72  88  69  38 116  90  41  87  97 102  71  25 112  96  81 101  94  77\n[145]  67  60  82 105  70  55  84  70  86  47  20  40  27  33  21  32  35  32\n[163] 108 108  69 114  65  28  91  54  67  80  61  48  57  29  82  53  28  49\n[181]  64  60  85  80  82 104  60  40  79  74  72  92  47  46  65  74  74  20\n[199]  76  40\n\ndf1 &lt;- data.frame(species, dbh, age)\ndf1\n\n\n  \n\n\n\nTo access values, we can use the same approaches as for matrices:\n\ndf1[1:12, 1:2]\n\n\n  \n\n\n\nbut can also access and filter the columns directly using their names like this:\n\ndf1$species\n\n  [1] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n  [7] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [13] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [19] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [25] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [31] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [37] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [43] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [49] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [55] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [61] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [67] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n [73] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n [79] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n [85] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n [91] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n [97] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[103] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[109] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[115] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[121] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[127] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[133] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[139] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[145] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[151] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[157] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[163] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[169] \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"   \n[175] \"sycamore\" \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\"\n[181] \"beech\"    \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"   \n[187] \"ash\"      \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"     \n[193] \"elm\"      \"maple\"    \"sycamore\" \"beech\"    \"ash\"      \"elm\"     \n[199] \"maple\"    \"sycamore\"\n\ndf1[df1$dbh &gt; 15, ]\n\n\n  \n\n\n\n\n2.3.1 Exercise\n\nUsing df1, select only entries corresponding to ash and maple with an age over 50 and a diameter less than 30.\nAdd a new column to the dataframe called “year”. Generate data for this column so that there are 10 different years and the same number of entries for each tree species per year.\n\n\ndf1\n\n\n  \n\n\nyear &lt;- rep(2015:2024, 20)\n\ndf1[,4] &lt;- year\n\ncolnames(df1)[4] &lt;- \"year\"\n\n\ndf1\n\n\n  \n\n\n\n\n\n\n\n\n\nTipTip\n\n\n\nUse the function rep for this exercise",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data structures</span>"
    ]
  },
  {
    "objectID": "Rintro3.html",
    "href": "Rintro3.html",
    "title": "3  Data, packages, and some more functions",
    "section": "",
    "text": "3.1 Setting up your working environment\nUsually when working in R, you want to look at your own data, and not generate it from random distributions. To read in a data file, we first need to tell R where the working directory is located.\nsetwd(\"/home/of22haqi/Documents/TEACHING/MEE-WS25-26/data/\")\nThe path will look different on your machine of course.\nNow that R knows where to find it, we are ready to read in a data file.\n# The table contains headers, and the fields are separated by commas\nbe &lt;-  read.table(\"data/butterfly_ecology.csv\", header = TRUE, sep = \",\")\n\n# Let's have a glimpse at the data \nhead(be)\nIn order to save your entire working environment, so you don’t have to re-run potentially time intensive pieces of your code, just save it and load it back into your work space the next time you use R.\nsave.image(\"myenv.Rdata\")\nYou can also use the panel “Environment” in RStudio to save and load your data.\nAll of the functions we used today are so “base R” functions, which means they come preinstalled with R. Lots of the functionality of R is in external packages which need to be installed manually. The majority of relevant packages are found on CRAN (The Comprehensive R Archive Network), and there is a special archive for packages relevant to the life sciences (Bioconductor). In order to install packages from CRAN, simply run\ninstall.packages(\"tidyverse\", dependencies = TRUE)\nHere, tidyverse is the package we want to install we ask to also install any packages that tidyverse may require to function. You can find a list of all packages currently installed in the packages tab in the panel on the bottom left in RStudio. It is good practise to keep the packages, as well as your R installation up to date.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "Rintro3.html#setting-up-your-working-environment",
    "href": "Rintro3.html#setting-up-your-working-environment",
    "title": "3  Data, packages, and some more functions",
    "section": "",
    "text": "Use a text editor outside of Rstudio to look at the data file as well. Why do you think this is a good format to store data in? WHat is the advantage to e.g., an Excel file? What does using a text file format mean for your data entry requirements?",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "Rintro3.html#functions",
    "href": "Rintro3.html#functions",
    "title": "3  Data, packages, and some more functions",
    "section": "3.2 Functions",
    "text": "3.2 Functions\nWe have already used plenty of functions. Most of them require at least an object an which to perform the function on, and may also have some options. For example, consider the following function:\n\nmean(be$range.size, na.rm = TRUE)\n\n[1] 261.4116\n\n\nmean is the function, be$range.size is the object (1 vector from the dataframe we just read into R) and na.rm = TRUE is the option to remove NAs from the vector before calculating the mean.\nIn some cases, you may want to do things to your data that cannot be addressed by a single function. In this case, you may have to perform a number of different operations on the dataset. If you are likely to use the same set of operations in the future, it may be advisable to use your own functions.\nA very simple example. Let’s assume the mean function didn’t exist and we would need to write our own.\n\nmean2 &lt;- function(x){\n  x &lt;- na.omit(x)\n  sum(x) / length(x) \n}\n\nmean2(be$range.size)\n\n[1] 261.4116\n\n\nWe define mean2 as a function that requires an object (here called x as an input). Looking into the function, we can see that it first removes the NAs from the object and next calculates the sum of x divided by the number of elements of x (this is how the mean is defined). Testing it, we can see that it gives the same result as the native mean function.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "Rintro3.html#loops",
    "href": "Rintro3.html#loops",
    "title": "3  Data, packages, and some more functions",
    "section": "3.3 Loops",
    "text": "3.3 Loops\nIn many cases, we need to apply a function t a number of elements. In this case, loops come in handy. In the simple examples below, the structure of a for loop is illustrated.\n\nfor(i in 1:10) # how often is the loop repeated\n{\n   print(i)    # what is to be done each iteration\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\nj&lt;-0\nfor(i in 1:5)\n{\n   j&lt;-i+j\n   print(j)\n}\n\n[1] 1\n[1] 3\n[1] 6\n[1] 10\n[1] 15\n\n\nObserve and try to explain what happens in each iteration to the variables used in these examples.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "Rintro3.html#plots",
    "href": "Rintro3.html#plots",
    "title": "3  Data, packages, and some more functions",
    "section": "3.4 Plots",
    "text": "3.4 Plots\nFor many use cases ggplot2 is the best approach of plotting, and we will get to know this package later. However, for very simple and quick plots, base R plotting functions are sufficient and superior to othe options because of simplicity and speed.\nScatter plots can be created by just naming the variables to be plotted against each other.\n\nplot(be$WSP_Female_average, be$ALT_Range)\n\n\n\n\n\n\n\n\nHistograms showing frequency distributions are also very easily generated\n\nhist(be$WSP_Female_average)",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "Rintro3.html#exercises",
    "href": "Rintro3.html#exercises",
    "title": "3  Data, packages, and some more functions",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\nUsing a loop, plot histograms for the columns “WSP_Female_average”, “Alt_Range”, “Alt_min”, and “range.size”.\nWrite a function that creates these plots with only the dataframe as argument.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data, packages, and some more functions</span>"
    ]
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "4  Tidyverse",
    "section": "",
    "text": "4.1 What is the tidyverse?\nWe will only be looking at a couple of functions from a 2 packages (dplyr & ggplot2). All functions are about data manipulation and visualisation and are especially well suited for exploring very large data sets.\nYou can install all tidyverse packages by running\ninstall.packages(\"tidyverse\", dependencies = TRUE)\n\n# Downloading packages -------------------------------------------------------\n- Downloading covr from CRAN ...                OK [169.7 Kb in 0.81s]\n- Downloading rex from CRAN ...                 OK [91.4 Kb]\n- Downloading lazyeval from CRAN ...            OK [81.5 Kb]\n- Downloading feather from CRAN ...             OK [8.3 Kb]\n- Downloading arrow from CRAN ...               OK [4 Mb in 0.15s]\n- Downloading assertthat from CRAN ...          OK [12.4 Kb]\n- Downloading mockr from CRAN ...               OK [20.4 Kb]\n- Downloading testthat from CRAN ...            OK [814.5 Kb]\n- Downloading brio from CRAN ...                OK [12.9 Kb]\n- Downloading desc from CRAN ...                OK [78.2 Kb]\n- Downloading pkgload from CRAN ...             OK [85.5 Kb]\n- Downloading pkgbuild from CRAN ...            OK [50.1 Kb]\n- Downloading rprojroot from CRAN ...           OK [58.5 Kb]\n- Downloading praise from CRAN ...              OK [6 Kb]\n- Downloading waldo from CRAN ...               OK [44.8 Kb]\n- Downloading diffobj from CRAN ...             OK [461.9 Kb]\nSuccessfully downloaded 16 packages in 4.9 seconds.\n\nThe following package(s) will be installed:\n- arrow      [22.0.0.1]\n- assertthat [0.2.1]\n- brio       [1.1.5]\n- covr       [3.6.5]\n- desc       [1.4.3]\n- diffobj    [0.3.6]\n- feather    [0.4.0]\n- lazyeval   [0.2.2]\n- mockr      [0.2.2]\n- pkgbuild   [1.4.8]\n- pkgload    [1.4.1]\n- praise     [1.0.0]\n- rex        [1.2.1]\n- rprojroot  [2.1.1]\n- testthat   [3.3.2]\n- tidyverse  [2.0.0]\n- waldo      [0.6.2]\nThese packages will be installed into \"~/work/MEE-WS25-26/MEE-WS25-26/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\nThe following required system packages are not installed:\n- cmake  [required by arrow]\nThe R packages depending on these system packages may fail to install.\n\nAn administrator can install these packages with:\n- sudo apt install cmake\n\n# Installing packages --------------------------------------------------------\n- Installing tidyverse ...                      OK [linked from cache]\n- Installing lazyeval ...                       OK [built from source and cached in 1.7s]\n- Installing rex ...                            OK [built from source and cached in 1.3s]\n- Installing covr ...                           OK [built from source and cached in 2.4s]\n- Installing assertthat ...                     OK [built from source and cached in 1.2s]\n- Installing arrow ...                          OK [built from source and cached in 3.3m]\n- Installing feather ...                        OK [built from source and cached in 2.5s]\n- Installing mockr ...                          OK [built from source and cached in 1.4s]\n- Installing brio ...                           OK [built from source and cached in 1.5s]\n- Installing desc ...                           OK [built from source and cached in 2.4s]\n- Installing pkgbuild ...                       OK [built from source and cached in 2.3s]\n- Installing rprojroot ...                      OK [built from source and cached in 1.3s]\n- Installing pkgload ...                        OK [built from source and cached in 2.9s]\n- Installing praise ...                         OK [built from source and cached in 1.0s]\n- Installing diffobj ...                        OK [built from source and cached in 7.1s]\n- Installing waldo ...                          OK [built from source and cached in 2.2s]\n- Installing testthat ...                       OK [built from source and cached in 24s]\nSuccessfully installed 17 packages in 4.2 minutes.\n(Remember, you can just add the answers into this document for future reference!)",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#what-is-the-tidyverse",
    "href": "tidyverse.html#what-is-the-tidyverse",
    "title": "4  Tidyverse",
    "section": "",
    "text": "A collection of R packages for data science\nAll packages share a “philosophy” about design and data structure\nAll packages are highly compatible and functions complement each other\n\n\n\n\n\nLet’s refresh what we learned earlier this week:\n\nWhat different types of data structures are used in R?\nWhich of these do you think is most likely to be used in the tidyverse?",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#our-data-set-for-today",
    "href": "tidyverse.html#our-data-set-for-today",
    "title": "4  Tidyverse",
    "section": "4.2 Our data set for today",
    "text": "4.2 Our data set for today\nWe will be looking at a data set of ecological traits of european butterflies. Download the table and read it into R.\n\n# The table contains headers, and the fields are separated by commas\nbe &lt;-  read.table(\"data/butterfly_ecology.csv\", header = TRUE, sep = \",\")\n\n# Let's have a glimpse at the data using head\nhead(be)\n\n\n  \n\n\n\nEach of the rows contains data for 1 European species, and the columns contain the following information:\n\n\n\n\n\n\n\n\n\nTrait abbreviation\nMeaning\nStates\nNotes\n\n\n\n\nOWS\nOverwintering stage\negg, larvae, pupae, adult\n\n\n\nGEN\nGenerations\naverage, min, max, range\n\n\n\nWSP\nWingspan\naverage, range\nMeasured in mm\n\n\nHSI\nHostplant index\nN/A\nMeasured from 0-1\n\n\nLEV\nLarval environment\nburied, ground layer, field layer, shrub layer, canopy layer\n\n\n\nELT\nEgg laying type\nsingle, small batch, large batch\n\n\n\nALT\nAltitude\nmin, range\n\n\n\nFM\nFlight months\naverage, range\n\n\n\nAFB\nAdult feeding behaviour\nherb flower, grass, shrub flower, honeydew, sap, animal, mineral\n\n\n\n\nNow that we are familiar with the dataset, lets look at some tidyverse functions.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#filter-for-filtering-data-frames",
    "href": "tidyverse.html#filter-for-filtering-data-frames",
    "title": "4  Tidyverse",
    "section": "4.3 filter() for filtering data frames",
    "text": "4.3 filter() for filtering data frames\nAs the name suggests, this is used to filter data frames, with a simple and efficient syntax:\n\n# first, we have to load the tidyverse packages\nlibrary(tidyverse, quietly = TRUE)\n\n# the command always takes a dataframe as first argument, and a filtering criterion as second argument\n# Here, we only consider butterflies that overwinter as eggs\nfilter(be, OWS_egg == 1)\n\n\n  \n\n\n\nThe filtering criterion can be specified using the methods you are already familiar with (e.g., &gt;, &gt;=, !=, %in%).\nNotice that the variable names can be used directly here, so instead of using be$OWS_egg, filter() lets you use OWS_egg directly. All tidyverse functions work like that. Let’s look at more complex filtering:\n\n# combine 2 filters with boolean \"AND\" ...\nfilter(be, OWS_egg == 1 , ALT_Min &gt; 500)\n\n\n  \n\n\n# ... or boolean \"OR\"\nfilter(be, OWS_egg == 1 | AFB_honeydew == 1)\n\n\n  \n\n\n\n\nNOTE\nfilter() (and many other tidyverse functions) return a data frame. In the tidyverse, these are called tibble() and behave slightly different to regular data frames. For our purposes however, these differences are not important.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#the-pipe-for-combining-commands",
    "href": "tidyverse.html#the-pipe-for-combining-commands",
    "title": "4  Tidyverse",
    "section": "4.4 The pipe %>% for combining commands",
    "text": "4.4 The pipe %&gt;% for combining commands\nThe filtering using filter() is very useful, but you can see that the commands can become very long when you have many filters. Also, trying out many different filters to see what they do with the data can be cumbersome. This where %&gt;% comes in really handy.\nThe “pipe” %&gt;% (keyboard shortcut: Ctrl+Shift+M) simply passes the result of one function to the next function. For the next function, one does not have to specify the data frame. Let’s see an example.\n\n# this is how we filtered our data frame earlier \nfilter(be, OWS_egg == 1)\n\n\n  \n\n\n# same command, this time using the pipe\nbe %&gt;%  \n  filter(OWS_egg == 1)\n\n\n  \n\n\n\nNote how in the second command, the output of be (which is our data frame) gets passed on to the filter() command. There, you don’t have to specify the name of the data frame again. The result of this can be piped further to other commands:\n\n# Multiple filters are connected by pipes\nbe %&gt;% \n  filter(OWS_egg == 1) %&gt;% \n  filter(LEV_ground_layer == 1) %&gt;% \n  filter(AFB_honeydew == 1)\n\n\n  \n\n\n# As always in R, assign the result to a new variable using \"&lt;-\" \nbe_filtered &lt;- be %&gt;% \n  filter(OWS_egg == 1) %&gt;% \n  filter(LEV_ground_layer == 1) %&gt;% \n  filter(AFB_honeydew == 1)\n\nNote how easy this command is to read (you could write it in a single line, but it’s much easier to follow with line breaks)! The usefulness of the pipe will become more obvious when we combine multiple different commands. In all the following examples, I will always use the pipe.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#sort-by-column-with-arrange",
    "href": "tidyverse.html#sort-by-column-with-arrange",
    "title": "4  Tidyverse",
    "section": "4.5 Sort by column with arrange()",
    "text": "4.5 Sort by column with arrange()\nThis doesn’t change the dataframe itself, it simply orders the columns (similar to the sort function in Excel):\n\n# sort by age (ascending) and weight (descending)\nbe %&gt;% \n  arrange(conserv.eu, -range.size)",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#select-columns-with-select",
    "href": "tidyverse.html#select-columns-with-select",
    "title": "4  Tidyverse",
    "section": "4.6 Select columns with select()",
    "text": "4.6 Select columns with select()\n\n# choose which columns to keep\nbe %&gt;% \n  select(species, range.size, conserv.eu, FM_Average, WSP_Female_average)\n\n\n  \n\n\n# or specify which columns to remove\nbe %&gt;% \n  select(-(OWS_egg:OWS_adult))\n\n\n  \n\n\n# contains is another useful command to select columns. \nbe %&gt;% \n  select(species, contains(\"LEV\")) %&gt;% \n  drop_na()\n\n\n  \n\n\n\nFuntions like contains can be powerful for filtering and selecting. starts_with and ends_with work just the same way and are equally useful.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#create-new-variables-with-mutate",
    "href": "tidyverse.html#create-new-variables-with-mutate",
    "title": "4  Tidyverse",
    "section": "4.7 Create new variables with mutate()",
    "text": "4.7 Create new variables with mutate()\nThis is a very powerful and flexible function that uses existing variables to create novel ones. Let’s look at a simple example\n\n# Create a new variable summarizing all the overwintering stages that are not adults\nbe %&gt;% \n  mutate(OWS_juvenile = 1-OWS_adult) %&gt;% \n  select(OWS_juvenile, OWS_adult) %&gt;% \n  drop_na()\n\n\n  \n\n\n# Determine how different the protection levels between EU and Europe and extract the species for which the difference is striking\nbe %&gt;% \n  mutate(protect_diff = abs(conserv.europe - conserv.eu)) %&gt;% \n  filter(protect_diff &gt; 2)",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#exercise",
    "href": "tidyverse.html#exercise",
    "title": "4  Tidyverse",
    "section": "4.8 Exercise",
    "text": "4.8 Exercise\n\nFrom our dataset, remove all butterflies with average wingspans larger than 60mm and smaller than 30mm. Only keep the species that have a conservation classification on the EU level. Only keep the species names and all variables associated with adult feeding, and store this in a new data frame. How many rows and columns does the new data frame have?\n\n\nnew_be &lt;- be %&gt;% \n  filter(WSP_Female_average &lt; 60) %&gt;% # filter1 \n  filter(WSP_Female_average &gt; 30) %&gt;% \n  drop_na(conserv.eu) %&gt;% \n  select(species, starts_with(\"AFB\")) \n\nnew_be\n\n\n  \n\n\n\n\nRe-calculate the generation range from the provided minima and maxima. Check if your calculations match the original range values given in the data.\n\n\nbe %&gt;% \n  mutate(GEN_Range2 = GEN_Max - GEN_Min) %&gt;% \n  select(species, GEN_Max, GEN_Min, GEN_Range2, GEN_Range) %&gt;% \n  mutate(GEN_compare = GEN_Range2 - GEN_Range)",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#group_by-and-summarise-as-powerful-data-exploration-tools",
    "href": "tidyverse.html#group_by-and-summarise-as-powerful-data-exploration-tools",
    "title": "4  Tidyverse",
    "section": "4.9 group_by() and summarise() as powerful data exploration tools",
    "text": "4.9 group_by() and summarise() as powerful data exploration tools\nAlthough dplyr has a simpler syntax overall, everything we have looked at so far could have been done fairly easily with base R functions: data frame filtering, sorting, and adding and removing columns. One of the strengths of dplyr is explorative data analysis, and this is where group_by() and summarize() are really helpful. We’ll only look at very simple examples today.\nWhen browsing through the complete data table, it is very hard to recognize any patterns. Let’s assume we wanted to compare the average wing span of butterflies with that overwinter as adults vs all other butterflies:\n\n# Are butterflies that overwinter as adults larger than other species?\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(OWS_adult) %&gt;% \n  summarise(mean_wsp = mean(WSP_Female_average))\n\n\n  \n\n\n\nAfter choosing which variable to group by (here: OWS_adult), summarise() then calculates a function for each group. In our simple example, there are 2 groups: 0 (not overwintering as adult) and 1 (overwintering as adult); and the function to be calculated is the mean of the female wing span. This is a very flexible set of functions, because you can group by multiple groups and also use summarise() with many different functions (e.g., mean(), sum(), min(), max(), median() – just to name a few). Let’s look at a more complex example:\n\n# Let's add another group. How large is the standard deviation? How large is each group?\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(OWS_adult, LEV_ground_layer) %&gt;% \n  summarise(mean_wsp = mean(WSP_Female_average),\n            sd = sd(WSP_Female_average),\n            group_size=n())\n\n`summarise()` has grouped output by 'OWS_adult'. You can override using the\n`.groups` argument.\n\n\n\n  \n\n\nbe %&gt;% \n  mutate(alt_bins = case_when(ALT_Min &gt; 500 ~ \"high\",\n                              ALT_Min &lt;= 500 ~ \"low\"))",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#more-exercises",
    "href": "tidyverse.html#more-exercises",
    "title": "4  Tidyverse",
    "section": "4.10 More exercises",
    "text": "4.10 More exercises\nUsing dplyr functions, determine\n\nIf butterflies overwintering as pupae have higher level of legal protection\n\n\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(OWS_pupae) %&gt;% \n  summarise(mean_conserve = mean(conserv.eu))\n\n\n  \n\n\n\n\nIf butterflies occurring at higher altitudes on average have a higher level of protection\n\n\nbe %&gt;% \n  drop_na() %&gt;% \n  mutate(ALT_cat = case_when(ALT_Min &lt; 200 ~ \"niedrig\",\n                            ALT_Min &gt; 1000 ~ \"hoch\",\n                            ALT_Min &lt;= 1000 & ALT_Min &gt;= 200 ~ \"mittel\" )) %&gt;% \n  group_by(ALT_cat) %&gt;% \n  summarise(mean_conserv = mean(conserv.eu))\n\n\n  \n\n\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(conserv.eu) %&gt;% \n  summarise(mean_ALT = mean(ALT_Min))\n\n\n  \n\n\n\n\nIf feeding on honeydew is more common in larger butterflies.\n\n\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(AFB_honeydew) %&gt;% \n  summarise(size = mean(WSP_Female_average))\n\n\n  \n\n\n\n\nHow many butterfly species are there per family?\n\n\nbe %&gt;% \n  drop_na() %&gt;% \n  group_by(family) %&gt;% \n  tally()\n\n\n  \n\n\n\nFor a–c also determine how many species belong to each group.",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "ggplot.html",
    "href": "ggplot.html",
    "title": "5  The ggplot2 package",
    "section": "",
    "text": "5.1 Very (!) brief introduction\nggplot2 is a graphing library, i.e., a tool to make graphs in R. Compared with base graphs and other graphics packages, it comes with a number of advantages:\nCompared with other packages the major drawbacks would be that it comes with a steep(ish) learning curve and is probably less intuitive for beginners. The reason is that ggplot2 doesn’t have fixed commands for scatterplots, boxplots, barplots, etc, but rather creates the plot in layers. The most important elements (or layers) of a plot in ggplot2 are:",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#very-brief-introduction",
    "href": "ggplot.html#very-brief-introduction",
    "title": "5  The ggplot2 package",
    "section": "",
    "text": "Beautiful!\nHighly customizable (which is not always necessary though)\nEasiest way to create very complex plots\nTightly integrated into the tidyverse\n\n\n\nData: as we are still in the tidyverse, this is always a data frame\nAesthetics: i.e., what you want to plot. Often, this will correpond to variables (columns) in your dataframe\nGeometric objects: i.e., how you want to plot the data. This can be points, bars, boxplots, lines, etc..\nFacets: more about this later\nAdditional (optional) adjustments: this includes themes that specify the overall design",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#building-up-the-plot",
    "href": "ggplot.html#building-up-the-plot",
    "title": "5  The ggplot2 package",
    "section": "5.2 Building up the plot",
    "text": "5.2 Building up the plot\nWe will start off with a very simple scatterplot and gradually increase the complexity to illustrate ggplot2 functionality.\n\n# data and packages\nlibrary(tidyverse, quietly = TRUE)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nbe &lt;-  read.table(\"data/butterfly_ecology.csv\", header = TRUE, sep = \",\")\n\n# simple plot\nbe %&gt;%                                # DATA\n  ggplot(aes(x = WSP_Female_average,  # AESTHETICS\n             y = range.size))   \n\n\n\n\n\n\n\n\nIn the above example, the data is the data frame that we have been using the whole time. Notice how we can simply pipe it to ggplot2. aes specifies our aesthetics, i.e., what we want to plot. What is missing?\n\n# simple scatter plot\nbe %&gt;%                               # DATA\n  ggplot(aes(x = WSP_Female_average, # Aesthetics\n             y = range.size)) +\n  geom_point()                       # Geometric object\n\n\n\n\n\n\n\n\nThe geometric object, i.e., how we want to plot our aesthetics. Notice that elements in ggplot2 are added with the + symbol (this is specific to ggplot2). We can add more geometric objects that will use the same aesthetics:\n\n# lets add another geom (a regression line), and also change the theme\nbe %&gt;%                               # DATA\n  ggplot(aes(x = WSP_Female_average, # Aesthetics\n             y = range.size)) +\n  geom_point() +                     # Geometric object\n  geom_smooth(method = \"lm\") +       # Another geometric object\n  theme_light()                      # Let's also change the theme\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nChanging the theme changes many layout options. For different applications, different themes might be appropriate. There are many additional themes available through packages such as ggthemr or ggthemes.\nA bit more on aesthetics: have you noticed that you only specify x and y once, and all geoms know what you want to plot. You can also specify additional aesthetics for each geom.\n\n# Add additional aesthetics, here: we want to plot the sonservation status. How? With colour! \n\nbe %&gt;%                                   # DATA\n  ggplot(aes(x = WSP_Female_average,     # Aesthetics\n             y = range.size)) +\n  geom_point(aes(color = conserv.eu)) +  # aesthetics specific to the points only\n  geom_smooth(method = \"lm\",\n              color = \"black\",\n              se = FALSE) +              \n  theme_light() +\n  scale_color_viridis_c()                # let's use some nicer colors                         \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nAesthetics can be added through colors or shapes",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#faceting",
    "href": "ggplot.html#faceting",
    "title": "5  The ggplot2 package",
    "section": "5.3 Faceting",
    "text": "5.3 Faceting\nSo far, we have cramped as much information as possible into the plot. This was useful to illustrate the functionality of ggplot2, but did not create very readable plots. Often, faceting is a better solution. The implementation in ggplot2 is very straightforward.\n\n# Same example as before, faceted over family\nbe %&gt;%                                   \n  ggplot(aes(x = WSP_Female_average,     \n             y = range.size)) +\n  geom_point(aes(color = conserv.eu)) + \n  geom_smooth(method = \"lm\",\n              color = \"black\",\n              se = FALSE) +              \n  theme_light() +\n  scale_color_viridis_c() +                \n  facet_wrap(~family, scales = \"free\")   \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# And now, faceting over 2 variables\nbe %&gt;%   \n  ggplot(aes(x = WSP_Female_average,     \n             y = range.size)) +\n  geom_point(aes(color = conserv.eu)) +  \n  geom_smooth(method = \"lm\",\n              color = \"black\",\n              se = FALSE) +              \n  theme_light() +\n  scale_color_viridis_c() +                \n  facet_grid(OWS_egg ~ family, scales = \"free\") # faceting\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThe above plot would need a little ‘cleaning up’. How would you do that?",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#some-common-plot-types",
    "href": "ggplot.html#some-common-plot-types",
    "title": "5  The ggplot2 package",
    "section": "5.4 Some common plot types",
    "text": "5.4 Some common plot types\nWe have looked at scatterplots, now let’s look at a number of other commonly used plots.\n\n# histograms\nbe %&gt;% \n  ggplot(aes(x = WSP_Female_average, fill = family)) +\n  geom_histogram(bins = 50) +\n  theme_light() +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n# better alternative are often density plots\nbe %&gt;% \n  ggplot(aes(x = WSP_Female_average, fill = family)) +\n  geom_density(alpha = 0.5, colour = NA) +\n  theme_light() +\n  scale_fill_brewer(palette = \"Set1\") \n\n\n\n\n\n\n\n# boxplots\nbe %&gt;% \n  ggplot(aes(y = WSP_Female_average, x = family)) +\n  geom_boxplot() +\n  theme_light() \n\n\n\n\n\n\n\n# better alternative are violin plots\nbe %&gt;% \n  ggplot(aes(y = WSP_Female_average, x = family)) +\n  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +\n  theme_light()",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#fine-tuning-plots",
    "href": "ggplot.html#fine-tuning-plots",
    "title": "5  The ggplot2 package",
    "section": "5.5 Fine tuning plots",
    "text": "5.5 Fine tuning plots\nWe now know how to plot some common chart types but most of these don’t look publishable yet. Lets return to one of our first examples and see how to polish it a little.\n\n# A publication ready plot\nbe %&gt;% \n  filter(family != \"Riodinidae\") %&gt;%\n  ggplot(aes(y = WSP_Female_average, x = family, color = family)) +\n  geom_boxplot(lwd = 1, outlier.shape = NA) +\n  geom_point(position = position_jitterdodge(jitter.width = 2), alpha = 0.5) +\n  theme_light() +\n  labs(title = \"Wing span across European butterfly families\",\n       y = \"Average wing span of female\")+ \n  theme(plot.title = element_text(face = \"bold\"),\n        axis.title.y = element_text(size = 12),\n        axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        strip.text = element_text(size = 11)) +\n  scale_color_brewer(palette = \"Set1\", name = \"Family\")",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "ggplot.html#exercise",
    "href": "ggplot.html#exercise",
    "title": "5  The ggplot2 package",
    "section": "5.6 Exercise",
    "text": "5.6 Exercise\nUsing ggplot2, explore how range size differs between butterfly families and plot check if butterflies with smaller ranges have higher protection status. Try to find appropriate plot types for this, use the help pages to find plot types that were not introduced to you yet. Explore other variables that may explain some trends in the data. Find a theme that you like! Remember, start with the data, add aesthetics (what do you want to plot), and then think about geometric objects (how do you want to plot the data). How can colour help in your visualisations? Does faceting make sense?\n\nbe %&gt;% \n  mutate(OWS_egg = as.factor(OWS_egg)) %&gt;% \n  ggplot(aes(x = conserv.europe, group = OWS_egg, fill = OWS_egg)) +\n  geom_bar(position = position_dodge()) \n\nWarning: Removed 37 rows containing non-finite outside the scale range\n(`stat_count()`).",
    "crumbs": [
      "`R`",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The `ggplot2` package</span>"
    ]
  },
  {
    "objectID": "unixIntro.html",
    "href": "unixIntro.html",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "",
    "text": "6.1 The Unix / Linux environment\nUnix and Linux (a variant of Unix) are operating systems (like Windows or macOS). They belong to a “family” of operating systems that share a common ancestor, have been around since 1969 and it’s not likely to disappear any time soon.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixIntro.html#the-unix-linux-environment",
    "href": "unixIntro.html#the-unix-linux-environment",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "",
    "text": "Commonly used among the scientific and technical community (e.g. servers and scientific clusters).\nmacOS is Unix-based system.\nMost supercomputers are powered by Unix-like operating systems.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixIntro.html#why-learn-unix-command-line",
    "href": "unixIntro.html#why-learn-unix-command-line",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "6.2 Why learn Unix command line?",
    "text": "6.2 Why learn Unix command line?\n\nIs the foundation of scientific computing (e.g. bioinformatics and data analysis)\nPowerful for working on large datasets and files\nHelps automate repetitive tasks (e.g. imagine you need to need to rename or modify 1,000 files?)\nEnables use of higher-powered computers elsewhere (clusters and servers/cloud-computing)",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixIntro.html#some-terminology",
    "href": "unixIntro.html#some-terminology",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "6.3 Some terminology",
    "text": "6.3 Some terminology\n\n\n\nimage1.png\n\n\nAs a user you can “communicate” with your Linux system either by a Graphical User Interface (GUI) or by typing instructions (commands) using a Command Line Interface (CLI). At first it might look quite complex and confusing but once you understand the concept and the basics then its quite simple and intuitive!\nCommand Line: is the written instructions we type.\nTerminal: also known as terminal emulator is the text-based environment (software) capable of taking input and providing output.\nShell: a program that interprets command-line input and executes commands. There are different shells available e.g bash, zsh, sh, csh etc. Each of them offering unique features and functionalities. Some are more basic and some are more fancy but all serve the same purpose, to interpret the commands provided by the user and output the results. The most commonly used is the bash shell.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixIntro.html#some-important-rules",
    "href": "unixIntro.html#some-important-rules",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "6.4 Some important rules",
    "text": "6.4 Some important rules\n\nBe aware of the case! The command line is case sensitive so be careful when typing. For example, typing Echo is not the same as echo, nor are the directory names “/Results” and “/results”.\nSpaces are having special use! The command line uses spaces as separators between arguments. Using spaces in filenames or directory names will certainly cause problems sooner or later. Avoid using names that contain spaces, but rather it’s better to use dashes (-) or underscores (_). e.g., “results_2026.txt” is preferred over “results 2026.txt”.\nApart from spaces there are several other characters (special characters) that can be used to perform special operations. See some examples bellow.\n\n\n\n\n\n\n\n\nCharacter\nDescription\n\n\n\n\n/\nDirectory separator, used to separate a string of directory names. Example: /usr/src/linux\n\n\n\\\nEscape — (backslash) prevents the next character from being interpreted as a special character. This works outside of quoting, inside double quotes, and generally ignored in single quotes.\n\n\n.\nCurrent directory. Can also “hide” files when it is the first character in a filename.\n\n\n..\nParent directory\n\n\n~\nThe tilde is a representation of the current user’s home directory.\n\n\n*\nRepresents 0 or more characters in a filename, or by itself, all files in a directory.\n\n\n?\nRepresents a single character in a filename.\n\n\n$\nExpansion — introduces various types of expansion: parameter expansion (e.g. $var or ${var}), command substitution (e.g. $(command)), or arithmetic expansion (e.g. $((expression))). More on expansions later.\n\n\n[ ]\nCan be used to represent a range of values, e.g. [0-9], [A-Z], etc. Example: hello[0-2].txt represents the names hello0.txt, hello1.txt, and hello2.txt\n\n\n|\nPipe — send the output from one command to the input of another command. This is a method of chaining commands together. Example: echo “Hello beautiful.” | grep -o beautiful.\n\n\n&gt;\nRedirect output of a command into a new file. If the file already exists, over-write it. Example: ls &gt; myfiles.txt\n\n\n&gt;&gt;\nRedirect and appends the output of a command onto the end of an existing file.\n\n\n&lt;\nRedirect a file as input to a program.\n\n\n;\nCommand separator. Allows you to execute multiple commands on a single line. Example: cd /var/log ; ls -l\n\n\n&&\nCommand separator as above, but only runs the second command if the first one finished without errors.\n\n\n&\nBackground – when used at the end of a command, run the command in the background (do not wait for it to complete).\n\n\n#\nComment — the # character begins a commentary that extends to the end of the line. Comments are notes of explanation and are not processed by the shell.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixIntro.html#accessing-your-terminal",
    "href": "unixIntro.html#accessing-your-terminal",
    "title": "6  Introduction to Linux Environment and Command Line.",
    "section": "6.5 Accessing your Terminal",
    "text": "6.5 Accessing your Terminal\nYou are using a Kubuntu Linux system. In Kubuntu, the terminal emulator is called Konsole. You can start it in any of the following ways:\n1. Press Ctrl + Alt + T to open Konsole instantly.\n2. Open the Krunner by pressing Alt + Space,  type Konsole, then press Enter.\n3. Open the Application Launcher → System → Konsole.\nNow you are ready to start typing your first commands!",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Linux Environment and Command Line.</span>"
    ]
  },
  {
    "objectID": "unixPart1.html",
    "href": "unixPart1.html",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "",
    "text": "7.1 Finding out where you are\nUnix systems, like most operating systems, store file locations in a hierarchical structure. In the UNIX file-system each file and directory has its own “address”, and that address is called a “path”.\nThere are two special locations in all Unix-based systems That you should be familiar. The “root” location is where the address system of the computer starts. The “home” location is where the current user’s location starts.\nBy default every time you open a new terminal you start in your own “home” directory(containing files and directories that only you can modify). The path of home directory is usually represented by the “~” character.\nBasic commands we will use\nThe pwd command in Linux is short for print working directory. It’s only function is to print the absolute path of the current directory. It’s handy when you’re not exactly sure what directory you’re in. So make it a good habit to get used to running the pwd command a lot.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart1.html#finding-out-where-you-are",
    "href": "unixPart1.html#finding-out-where-you-are",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "",
    "text": "# Example. Try running pwd. What do you see?\npwd\n# What do you see if you run PWD instead? \nPWD\n# Try now to run this \"echo $PWD\". The command echo just prints the parameters we give it. The $PWD is a environment variable and we will discuss about their use a bit later on.\necho $PWD",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart1.html#the-command-ls",
    "href": "unixPart1.html#the-command-ls",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "7.2 The command ls",
    "text": "7.2 The command ls\nls is short for list, and is used to list the files and sub-directories in your present working directory or some other directory if you specify one.\n# Examples\n# List the files and directories in your current directory\nls\n# or\nls .\n# ls can accept several options. Try running the following commands and observe how their output differs from the previous one.\nls -l\n# or\nls -lh\n# You can use ls to list the contents of any directory. Try the following.\nls -l /etc \n\n\n\n\n\n\nNoteNote\n\n\n\nI. The anatomy of a command (or command syntax)\nEach command is usually composed of three parts:\n\nThe command itself\nThe options: These are optional parameters that can be used to customise the behavior of a command. (e.g. on the previous examples ls -l shows the list of files in a long format)\nThe arguments: specify the target of the command. (e.g. on the previous example ls -l /etc you instructed the command to list the contents of the /etc directory)\n\nII. Getting help\nMost Unix commands can accept several parameters. How do we know which ones to use and why? Luckily, most Unix commands have built-in help documentation that we can access by providing –help as the only argument.\nTry for example: ls --help\nAnother way to access the documentation for a command is by using the man command and providing the command’s name as an argument. For example:\nman ls",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart1.html#relative-vs-absolute-path-and-getting-help",
    "href": "unixPart1.html#relative-vs-absolute-path-and-getting-help",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "7.3 Relative vs absolute path and getting help",
    "text": "7.3 Relative vs absolute path and getting help\nThere are two ways to specify the path (the file’s address on the computer):\n\nAn absolute path starts from a fixed location, either the root directory (/) or the home directory (~/). Note: A “full path” usually refers to an absolute path that starts from the root (/).\nA relative path starts from your current directory.\n\n\nWhen working at the command line, it’s important to always be aware of your current location in the system. One of the most common mistakes is trying to operate on a file that isn’t where you think it is. To avoid this, it’s good practice to use absolute paths, which clearly specify a file’s exact location regardless of where you are.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart1.html#moving-around",
    "href": "unixPart1.html#moving-around",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "7.4 Moving around",
    "text": "7.4 Moving around\nOne of the most commonly used commands in Linux is the change directory command, or cd. It allows you to change your working directory from the current location to another directory you want to navigate to. The cd command takes a positional argument: the path (address) of the directory you want to move into. This path can be either absolute or relative. Let’s try moving from our current directory to a directory present in your home directory called Documents.\n# The relative way\ncd Documents\n# The absolute way (~ stands for /home/&lt;user&gt;/). Can you see the change in your command prompt?\ncd ~/Documents\n# But how do we go back “up” to the parent directory? We can use the \"..\" special characters that act as a relative path, telling the system to move up one directory from our current location.\ncd ..\n# When you need to navigate back to the previous working directory from the current working directory, you can use the \"–\" option.\ncd -\n# Note: running the cd command without any arguments will always bring you back to your home\ncd",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart1.html#exercise",
    "href": "unixPart1.html#exercise",
    "title": "7  Part 1. Your first Unix commands - Navigating the Unix File-System Structure",
    "section": "7.5 Exercise",
    "text": "7.5 Exercise\nPractice moving around the filesystem with cd and listing directory contents with ls, including navigating by relative and absolute paths or using special characters “..” . Use pwd frequently to see your current working directory. Practice navigating home with cd.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Part 1. Your first Unix commands - Navigating the Unix File-System Structure</span>"
    ]
  },
  {
    "objectID": "unixPart2.html",
    "href": "unixPart2.html",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "",
    "text": "8.1 Creating new directories and files\nYou can create a new directory using the mkdir command. It takes as a parameter a relative or absolute path to the directory to create\nExercise\nIn the previous example we created the two directories in two separate steps. Can we do it in one step instead? (check the help page for mkdir command).\nNow that we saw how to create a new directory lets see how we can create a new file. There are several ways to do this in Linux command line but we will start with the basic one. The command touch will create a new, empty file.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart2.html#creating-new-directories-and-files",
    "href": "unixPart2.html#creating-new-directories-and-files",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "",
    "text": "# Let's try some examples. From your home directory navigate to Documents/ and create 2 new nested sub-directories with the names projects and project1\npwd\ncd Documents\nmkdir projects\ncd projects\nmkdir projects1\npwd\n# Try to create a new directory with the same name e.g. projects1. What do you see?\n\n\n\n# Create an Empty File within the new directory project1.\ntouch notes.txt\n# can you do it if you are outside the project1 directory?",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart2.html#move-or-rename-a-file-or-directory",
    "href": "unixPart2.html#move-or-rename-a-file-or-directory",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "8.2 Move or Rename a File or Directory",
    "text": "8.2 Move or Rename a File or Directory\nThe mv command serves for both moving and renaming files and directories. Works by specifying a “source_path” and a “destination_path”, wheres “source_path” is the path (absolute or relative) of the file/directory to move or rename, and “destination_path” is the new name or location to give it.\nCopying files and directories is similar operation, except that the original file or directory is not removed! We will use the cp command for this.\n\nNOTE: copying, moving or renaming files at the command line will overwrite files if they have the same name!!\n\nLet’s try them both.\n# move the notes.txt file one directory up assuming your current directory is project1\nmv notes.txt ../notes.txt\n# rename the notes.txt to README.txt\nmv ../notes.txt ../README.txt\n# copy the README.txt file to project1 directory as README1.txt\ncp ../README.txt ./README1.txt\nExercise\nTry to make a copy of the complete project1 directory on the same parent location with the name project2. What do you see?\n\n\n\n\n\n\nNoteNote\n\n\n\nWildcards: friend and foe at the command prompt.\nAs we saw earlier some characters have special use in Unix command line. For example:\n\nthe asterisk character “*” represents 0 or more characters in a filename, or by itself, all files in a directory.\nthe square brackets […] can be used define a range of values e.g. [0-9], [A-Z], etc.\nthe question mark “?” can represent any single character.\n\nThese characters can be used as “Wildcards” to perform operations on multiple files at the same time. Lets see some examples.\n# Create a directory with the name wildcard_practice and, inside it, create some empty files.\nmkdir wildcard_practice\ncd wildcard_practice\ntouch file1.txt file2.txt file10.txt\ntouch image1.png image2.png imageA.png\ntouch data_2022.csv data_2023.csv data_2024.csv\n# List all the .txt files\nls *.txt\n# create a directory called data and move the .csv files into data/\nmkdir data\nmv *.csv data/\nExercise List only the .csv files with years 2022 or 2023",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart2.html#delete-remove-files-and-directories",
    "href": "unixPart2.html#delete-remove-files-and-directories",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "8.3 Delete (remove) files and directories",
    "text": "8.3 Delete (remove) files and directories\n\n\n\n\n\n\nWarningWARNING!!\n\n\n\nUsing the rm command permanently deletes files and directories without moving them to a trash or recycle bin. This action cannot be undone! Whenever you use the rm command, ALWAYS double-check your syntax.\n\n\n# Lets remove some unwanted files and directories\nrm ~/Documents/projects/README.txt\n# the command rmdir can remove an empty directory, so it is safer!\nmkdir test_dir\nrmdir test_dir\n# The dangerous way. Use rm recursively \"-r\" to remove a non-empty directory. BE CAUTIOUS! YOU HAVE BEEN WARNED!\nrm -r ~/Documents/projects/project1\n# check the help page for rm command. Is there a safer way to do this? \nExercise\n\nCreate a directory data.\nInside data, create three empty files: sample1.txt, sample2.txt, sample3.txt\nCopy sample1.txt into a new directory called backup.\nRename sample2.txt to s2.txt.\nRemove sample3.txt.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart2.html#viewing-and-inspecting-files",
    "href": "unixPart2.html#viewing-and-inspecting-files",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "8.4 Viewing and inspecting Files",
    "text": "8.4 Viewing and inspecting Files\nSometimes we want to quickly look at files, either to inspect their structure or to get some basic information about their contents. These are some commands we can use to do so.\n\n\n\nCommand\nDescription\n\n\n\n\ncat\nprint entire file\n\n\nless\nscroll through file\n\n\nhead\nshow first n lines\n\n\ntail\nshow last n lines\n\n\nwc\ncount (word count)\n\n\n\n# Lets use the file \"butterfly_ecology.csv\" you previously used with R.\n# You can either navigate to the folder you saved the file copy it to a new directory.\n# You can use the \"cat\" command for viewing the contents of a file\ncat butterfly_ecology.csv\n# Another command for viewing the contents of a file is \"less\". This command allows to scroll through the document and view it line my line or page by page. We can even do some text searching. To exit less, press q (for quit).\nless butterfly_ecology.csv\n# However, most of the time we only need to see part of a file rather than the entire file. The commands \"head\" and \"tail\" come in handy. These commands print only the first (head) or the last (tail) lines of a file.\nhead butterfly_ecology.csv\ntail butterfly_ecology.csv\n# or you can specify the number of lines to print (by default will print 10)\nhead -n 2 butterfly_ecology.csv\ntail -n 3 butterfly_ecology.csv\n# The command wc (word count) is useful for counting how many lines, words, and characters there are in a file.\nwc butterfly_ecology.csv\n# Can you find an option for wc that will let us get only the number of lines of the file? \n\n\n\n\n\n\nNoteNote\n\n\n\nThe cat command can also be used to create new files or to concatenate existing files. Lets try:\ncat &gt; file1\nStefanos\n# Exit by pressing Ctrl + D\ncat &gt; file2\nsome random text\n# Exit by pressing Ctrl + D\ncat file1 file2 &gt; file3",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart2.html#a-text-editor-for-the-terminal",
    "href": "unixPart2.html#a-text-editor-for-the-terminal",
    "title": "8  Part 2. Working with Files and Directories",
    "section": "8.5 A text editor for the terminal",
    "text": "8.5 A text editor for the terminal\nA simple text editor available on most systems is nano. To run it, simply specify a file name to edit. If the file doesn’t exist already, it will be created after saving. \nnano NOTES.txt",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Part 2. Working with Files and Directories</span>"
    ]
  },
  {
    "objectID": "unixPart3.html",
    "href": "unixPart3.html",
    "title": "9  Part 3. Redirection, Pipes, and Text Processing in Unix",
    "section": "",
    "text": "9.1 Redirecting and piping\nRedirection and piping are fundamental features of the UNIX command line that allow us to create powerful workflows for automating tasks. By default, when we run a command, its output is printed to the screen (the terminal). In many situations, however, we may want to save this output to a file or pass it directly to another command.\nWe have already seen how a command output can be redirected to a file. For example: cat file1 file2 &gt; combined_file. In this command, the redirection operator &gt; tells the shell to send the output of cat to a new file called combined_file instead of displaying it on the screen. Let look at another example.\nWhile redirection allows us to save a command’s output to a file, UNIX also allows us to connect commands directly to one another. We can send the output of one command directly as input to another using the pipe (|) operator.\nExercise",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Part 3. Redirection, Pipes, and Text Processing in Unix</span>"
    ]
  },
  {
    "objectID": "unixPart3.html#redirecting-and-piping",
    "href": "unixPart3.html#redirecting-and-piping",
    "title": "9  Part 3. Redirection, Pipes, and Text Processing in Unix",
    "section": "",
    "text": "# list the files in the /etc directory and save the output to a file called etc_content.txt.\nls /etc &gt; etc_content.txt\nless etc_content.txt\n\n\n\n\n\n\nWarningWARNING!!\n\n\n\nIt’s important to remember that the &gt; operator will overwrite a file if it already exists. If you want to append an output to an existing file, rather than overwrite it, you can use instead &gt;&gt;.\n\nTry it out yourself!\n\n\n\n\n#list only the first 10 files of the /etc directory\nls /etc | head -n 10\n\n\nUsing the pipe operator, find a way to count all contents (files and directories) in the /etc directory.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Part 3. Redirection, Pipes, and Text Processing in Unix</span>"
    ]
  },
  {
    "objectID": "unixPart3.html#cut-sort-and-uniq",
    "href": "unixPart3.html#cut-sort-and-uniq",
    "title": "9  Part 3. Redirection, Pipes, and Text Processing in Unix",
    "section": "9.2 cut, sort, and uniq",
    "text": "9.2 cut, sort, and uniq\nThe cut command is used for extracting specific sections from lines of text in a file or piped data. It’s a great tools for or data manipulation. Lets try some examples:\n# Selecting fields separated by a delimiter\necho \"name,age,city,country\" | cut -d ',' -f 3\n# lets manipulate some real data\ncat butterfly_ecology.csv | cut -d ',' -f 1,2 | head\n# you can even change the delimiter in the output\ncat butterfly_ecology.csv | cut -d ',' -f 1,2  --output-delimiter $'\\t' | head\n# or\ncat butterfly_ecology.csv | cut -d ',' -f 1,2,5-7  --output-delimiter $'\\t' | head\nThe sort command is used to arrange the lines of text files in a specified order, such as alphabetically or numerically. It can also handle options for sorting in reverse order or by specific columns. NOTE: sort command will not modify your file, it will only print the reordered content on the terminal! However, you can specify redirect the output to a separate file.\ncat butterfly_ecology.csv | cut -d ',' -f 1-3 | sort\ncat butterfly_ecology.csv | cut -d ',' -f 1-3 | sort -t ',' -k3 | less\nThe uniq command in Linux is used to filter out repeated lines from a text file or standard input, displaying only unique entries or counting repetitions. It works best when the input is sorted, as it only removes adjacent duplicate lines.\n# families are represented in the butterfly_ecology.csv data?\ncat butterfly_ecology.csv | cut -d ',' -f 2 | sort | uniq\nExercise\n\nCan you use cut, sort and uniq commands to count the number of species per family species per family?",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Part 3. Redirection, Pipes, and Text Processing in Unix</span>"
    ]
  },
  {
    "objectID": "unixPart3.html#grep-and-regular-expressions",
    "href": "unixPart3.html#grep-and-regular-expressions",
    "title": "9  Part 3. Redirection, Pipes, and Text Processing in Unix",
    "section": "9.3 grep and regular expressions",
    "text": "9.3 grep and regular expressions\nThegrep (global regular expression) command in Linux is used to search for specific patterns or strings within files and display the matching lines. It is a powerful tool for text processing and can be customized with various options to refine search results. The basic usage is: grep “searchword” filename\n# Let's say you wished to identify every line which contain the string \"Papilionidae\" from the butterfly_ecology.csv\ngrep 'Papilionidae' butterfly_ecology.csv\n# We can find the number of lines that matches the given string/pattern instead\ngrep -c 'Papilionidae' butterfly_ecology.csv\n# Use -f  option to read patterns from a file\ncat &gt; family.txt\nPapilionidae\nHesperiidae\n# exit by pressing Ctrl + D\ngrep -f family.txt butterfly_ecology.csv\n# We can search for patterns in multiple files (e.g. all the files in the directory)\ngrep 'Papilionidae' *\ngrep command is particularly powerful when used in combination with Regular Expressions. A regular expression (regex) in Linux is a sequence of characters that defines a search pattern, similar to the wildcards, and are commonly used for searching and manipulating text.\nExercises\n\nIn the butterfly_ecology.csv file find all “Aglais” species and save the fields species, family, range.size in a new file.\nThe shell keeps a record of the commands you have previously run. You can display this list using the history command. Using this information, determine how many times you have used the ls command in your shell history. Hint: You may need to combine history with other command-line tools such as grep.",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Part 3. Redirection, Pipes, and Text Processing in Unix</span>"
    ]
  },
  {
    "objectID": "unixPart3.html#awk",
    "href": "unixPart3.html#awk",
    "title": "9  Part 3. Redirection, Pipes, and Text Processing in Unix",
    "section": "9.4 awk",
    "text": "9.4 awk\nawk is the Unix command to work with tabular data. The basic awk syntax is: awk [options] ‘pattern {action}’ input-file &gt; output-file\nawk  -F ',' '{print $0}' butterfly_ecology.csv\n\nawk -F ',' '$3 &gt; 1000 && $3 != \"NA\" {print $0}' butterfly_ecology.csv\n\nawk -F ',' '$3 &gt; 1000 && $3 != \"NA\" {print $1, $3}' butterfly_ecology.csv\n\nawk -F ',' '{if($3 &gt; 1000 && $3 != \"NA\") {print $1\":::\"$3}}' butterfly_ecology.csv\nA more complex example\nUsing only command line try calculate the average range.size for each family separately and store this information in a new file.\ngrep -v \"^species\" butterfly_ecology.csv | \\\nawk -F ',' '\n$3 != \"NA\" {\n  sum[$2] += $3\n  count[$2]++\n}\nEND {\n  for (family in sum) {\n    print family, sum[family] / count[family]\n  }\n}\n' OFS=',' &gt; average_range_by_family.csv",
    "crumbs": [
      "UNIX",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Part 3. Redirection, Pipes, and Text Processing in Unix</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart1.html",
    "href": "NGSanalysisPart1.html",
    "title": "10  Part 1. Installing Bioinformating tools and the Conda Package Manager",
    "section": "",
    "text": "10.1 What is Conda and why is needed\nAnalysis of Next-Generation Sequencing (NGS) data relies on specialized bioinformatics tools (e.g., FastQC, BWA, SAMtools).\nThese tools are often developed by different people, in different programming languages, and with different software dependencies, and installing them is not always straightforward (or at least it used to be).\nConda is a cross-platform package/tool and environment managing system that runs on Windows, macOS, and Linux.\nIt allows to:",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Part 1. Installing Bioinformating tools and the Conda Package Manager</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart1.html#what-is-conda-and-why-is-needed",
    "href": "NGSanalysisPart1.html#what-is-conda-and-why-is-needed",
    "title": "10  Part 1. Installing Bioinformating tools and the Conda Package Manager",
    "section": "",
    "text": "Install bioinformatics tools and not only - No need to compile software from source, after all we all have other things to worry about!\nAutomatically resolve dependencies - No need to worry about your missing library!\nCreate isolated software environments - Less chances to mess up with the rest of the software or the system itself!\n\n\n10.1.1 Installing and setting-up a conda environment in your linux system\nFo the purpose of this course we will use the miniforge minimal installer. Use your terminal window (konsole) to download the miniforge installer by running the following command. Yes! you can use your terminal to download files from the web. For this we will use the UNIX command wget. Feel free to copy paste the command to avoid typos.\nwget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nand run the script like this:\nbash Miniforge3-$(uname)-$(uname -m).sh\nNow follow the instructions and accept the license terms. When prompt confirm the installation location “/home/idiv/miniforge3”.\nReply yes to “Proceed with initialaization?”\nCongratulations! You have installed conda. But in order for the installation to take effect you should re-load (restart) your terminal or run the following command:\nsource .bashrc\nRun the following command to prevent the activation of the base conda environment on startup. This saves you from having problems later!\nconda config --set auto_activate_base false\nNow it is time to configure some settings, such as adding the necessary channels. Software packages are stored in locations called channels. Most bioinformatics packages are available through the bioconda channel.\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\nconda config --show channels\nCreate a conda environment for installing the necessary packages/tools. You can use either conda or mamba command. Mamba is a faster implementation of conda designed to improve the speed of package installation and environment management.\nFor simplicity, we will create our conda environment using an environment.yaml file, which contains a list of the packages required for this course. You will need to download the environment.yaml file from STUDIP and place it in your home directory.\n# Create the environment and install required packages. It might take a few minutes!\nconda env create -f environment.yaml\n# Inspect the environment is there\nconda info -e\n# Activate the environment. You can deactivate the environment using the comand \"conda deactivate\"\nconda activate mlu2026\nAlternatively, you can create an empty conda environment and then install the required packages/tools. You can search for bioconda packages here.\n# using mamba\nmamba create -n mlu2026 # This command will create an empty environment with the name \"mlu2026\". You can use any name for your environment, just avoid using the space character or any other special character!\n# similarly using conda\nconda create -n mlu2026\n# You can now activate your environment using one of the following commands.\nmamba activate mlu2026\n# or\nconda activate mlu2026\nHere you can find a conda-cheatsheet that you can use as a quick reference for managing your Conda environments.",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Part 1. Installing Bioinformating tools and the Conda Package Manager</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart2.html",
    "href": "NGSanalysisPart2.html",
    "title": "11  Part 2. NGS data Quality Control",
    "section": "",
    "text": "11.1 Obtain some high-throughput sequencing data\nThis practical will provide hands-on experience with quality control of high-throughput sequencing data. You will learn how to:\nFor this practical we will need to download some training sequencing data. We will use the following data (Bioproject PRJNA675888) associated with this article:\nIllumina: SRA paired-end dataset SRR13070681\nNanopore: SRA ONT dataset SRR13070731\nFirst you will need to create a data/ directory in your home folder. Within this directory create two sub-directories one for Illumian and one for the nanopore data.\nOption 1. Browser Navigate to the European Nucleotide Archive (ENA) and search for the sra accession numbers (). Download the files and move them to the respective directory.\nOption 2. You can use the command line to download the data.",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Part 2. NGS data Quality Control</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart2.html#obtain-some-high-throughput-sequencing-data",
    "href": "NGSanalysisPart2.html#obtain-some-high-throughput-sequencing-data",
    "title": "11  Part 2. NGS data Quality Control",
    "section": "",
    "text": "mkdir -p ~/data/illumina\nmkdir -p ~/data/nanopore\n\n\n# For the Illumina dataset\ncd ~/data/illumina\nwget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR130/081/SRR13070681/SRR13070681_1.fastq.gz\nwget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR130/081/SRR13070681/SRR13070681_2.fastq.gz\n# For the nanopore dataset\ncd ~/data/nanopore\nwget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR130/031/SRR13070731/SRR13070731_1.fastq.gz\n\n\n\n\n\n\nNoteNOTE\n\n\n\nWhat do the _1 and _2 in the Illumina dataset mean?\nMost Illumina sequencing is paired-end, meaning that after DNA fragmentation, both ends of each fragment are sequenced. This produces two reads for each DNA fragment: one read from one end of the fragment (_1, read 1) and a second read from the opposite end (_2, read 2).\n\n\n\npaired-end reads",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Part 2. NGS data Quality Control</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart2.html#short-read-data-qc-illumina",
    "href": "NGSanalysisPart2.html#short-read-data-qc-illumina",
    "title": "11  Part 2. NGS data Quality Control",
    "section": "11.2 Short-read data QC (Illumina)",
    "text": "11.2 Short-read data QC (Illumina)\nWe can inspect the fastq files\n# make sure you are directory ~/data/illumina\npwd\n# read the 10 first sequences\nzcat SRR13070681_1.fastq.gz | head -40\nWe can now generate some quality metrics for our data using the tool FastQC. For each file, FastQC will produced both a .zip archive containing all the plots, and a html report. You can run FastQC on the two files together or individually.\nmkdir fastqc_output\nfastqc -o fastqc_output *.fastq.gz\nQuestions:\n\nHow many total reads are in both files?\nWhat is the length of the read?\nWhich read files is of better quality?\n\n\n11.2.1 Quality control\nQuality control generally comes in two forms: 1. Trimming: involves removing poor quality bases from the reads (usually the ends) 2. Filtering: involves removing whole sequences either due to poor quality or they are too short\nTo carry this out we will use sickle. Let’s first have a look on the documentation page of sickle.\nsickle --help\n#  You can run now sickle with the Illumina reads using the following command.\nsickle pe -t sanger -f SRR13070681_1.fastq.gz -r SRR13070681_2.fastq.gz -o SRR13070681_1_Q28_MinL100.fastq.gz -p SRR13070681_2_Q28_MinL100.fastq.gz -s SRR13070681_unpaired.fastq.gz -q 28 -l 100\nWe can now re-run fastqc on the trimmed dataset.\nmkdir sickle_fastqc_output\nfastqc -o sickle_fastqc_output SRR13070681_*_Q28_MinL100.fastq.gz\nBonus. We can use the tool MultiQC to aggregate all the FastQC reports into one html report.\nmultiqc ~/data/illumina/fastqc_output ~/data/illumina/sickle_fastqc_output",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Part 2. NGS data Quality Control</span>"
    ]
  },
  {
    "objectID": "NGSanalysisPart2.html#long-read-data-qc-oxford-nanopore",
    "href": "NGSanalysisPart2.html#long-read-data-qc-oxford-nanopore",
    "title": "11  Part 2. NGS data Quality Control",
    "section": "11.3 Long-read data QC (Oxford Nanopore)",
    "text": "11.3 Long-read data QC (Oxford Nanopore)\nExercise\nCheck the quality of the Nanopore dataset. How does it differ from the Illumina reads?\n\n\n\n\n\n\nNoteNOTE\n\n\n\nSubsampling the sequencing data\nSometimes ngs data can be quite large. In this cases it is useful to downsample the data to a more manageable dataset.\nWe can use the tool seqkit to do this.\n# we can do this by number\nzcat file.fastq.gz | seqkit sample -n 100000 -o sample.fastq.gz\n# or by proportion e.g. 10%\nzcat file.fastq.gz | seqkit sample -p 0.1 -o sample.fastq.gz",
    "crumbs": [
      "NGSanalysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Part 2. NGS data Quality Control</span>"
    ]
  }
]